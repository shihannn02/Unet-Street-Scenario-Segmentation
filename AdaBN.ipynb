{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea44509-8ac0-461c-86c4-9b65bf820cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 4 experimentation: Unsupervised domain adaptation using adaptive batch normalization\n",
    "# major library dependencies: jupyter, numpy, matplotlib, pytorch, scikit-image, pillow\n",
    "\n",
    "# Fine-tuning with Pseudo-ground Truth\n",
    "import torch\n",
    "from dataset import camvidLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import data_aug as aug\n",
    "import torch.nn.functional as F\n",
    "from unet import UNet\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imsave\n",
    "\n",
    "device = 'cpu' # can be set to \"cuda\" if you have a GPU\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "\n",
    "data_root = './CamVid/cloudy'\n",
    "test_data = camvidLoader(root=data_root, split='test', is_aug=False, img_size = [256, 256], is_pytorch_transform=True)\n",
    "\n",
    "num_classes = 14 # number of classes is always 14 for this project.\n",
    "labels = ['Sky', 'Building', 'Pole', 'Road', 'LaneMarking', 'SideWalk', 'Pavement', 'Tree', 'SignSymbol', \n",
    "          'Fence', 'Car_Bus', 'Pedestrian', 'Bicyclist', 'Others']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b77370",
   "metadata": {},
   "source": [
    "## Load parameters, model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda3088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parameters\n",
    "batch_size = 4\n",
    "num_workers = 8\n",
    "lr = 5e-6\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95e2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pre-trained unet model\n",
    "unet_model = UNet(3, num_classes, width=32, bilinear=True)\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "unet_model.load_state_dict(unet.state_dict())\n",
    "unet_model = unet_model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(unet_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9118bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "aug_obj = aug.Compose([aug.RandomHorizontalFlip(), aug.RandomResizedCrop(256),\n",
    "                   aug.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4)])\n",
    "\n",
    "train_dataset = camvidLoader(root=data_root, split='train', is_aug=True, img_size = [256, 256], \n",
    "                             is_pytorch_transform = True, aug = aug_obj) \n",
    "train_loader = DataLoader(train_dataset, num_workers=num_workers, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_dataset = camvidLoader(root=data_root, split='val', is_aug=False, img_size = [256, 256], \n",
    "                             is_pytorch_transform = True, aug = None) \n",
    "val_loader = DataLoader(val_dataset, num_workers=num_workers, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_data, num_workers=num_workers, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3931d52",
   "metadata": {},
   "source": [
    "## Implement model finetuning using AdaBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function that computes the entropy map for the unet output\n",
    "def compute_entropy_map(model_output):\n",
    "\n",
    "    pixel_entropy = []\n",
    "    \n",
    "    for idx in range(0, model_output.shape[0]):\n",
    "    \n",
    "        # output size is 14*256*256\n",
    "        probs = F.softmax(model_output[idx], dim=0)\n",
    "\n",
    "        # calculate the entropy for each pixel\n",
    "        epsilon = 1e-5\n",
    "        entropy = -torch.sum(probs * torch.log(probs + epsilon), dim=0)\n",
    "        pixel_entropy.append(entropy.cpu().detach().numpy())\n",
    "\n",
    "    return pixel_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch = 0 | batch = 0 | loss = 0.40610939264297485\n",
      "train epoch = 0 | batch = 2 | loss = 0.3450988531112671\n",
      "train epoch = 0 | batch = 4 | loss = 0.34040388464927673\n",
      "train epoch = 0 | batch = 6 | loss = 0.3558237552642822\n",
      "train epoch = 0 | batch = 8 | loss = 0.3471675217151642\n",
      "train epoch = 0 | batch = 10 | loss = 0.3194240927696228\n",
      "train epoch = 0 | batch = 12 | loss = 0.39745572209358215\n",
      "train epoch = 0 | batch = 14 | loss = 0.3933342695236206\n",
      "train epoch = 0 | batch = 16 | loss = 0.3413313925266266\n",
      "In epoch 0, the train loss is: 0.36306368311246234, the val loss is: 1.305429220199585\n",
      "train epoch = 1 | batch = 0 | loss = 0.3962474465370178\n",
      "train epoch = 1 | batch = 2 | loss = 0.4062955379486084\n",
      "train epoch = 1 | batch = 4 | loss = 0.34931445121765137\n",
      "train epoch = 1 | batch = 6 | loss = 0.3907968997955322\n",
      "train epoch = 1 | batch = 8 | loss = 0.3547840118408203\n",
      "train epoch = 1 | batch = 10 | loss = 0.37394607067108154\n",
      "train epoch = 1 | batch = 12 | loss = 0.3365594744682312\n",
      "train epoch = 1 | batch = 14 | loss = 0.32207903265953064\n",
      "train epoch = 1 | batch = 16 | loss = 0.3510887920856476\n",
      "In epoch 1, the train loss is: 0.3629322035445107, the val loss is: 1.2757074236869812\n",
      "train epoch = 2 | batch = 0 | loss = 0.40623772144317627\n",
      "train epoch = 2 | batch = 2 | loss = 0.39640676975250244\n",
      "train epoch = 2 | batch = 4 | loss = 0.41153162717819214\n",
      "train epoch = 2 | batch = 6 | loss = 0.3403034806251526\n",
      "train epoch = 2 | batch = 8 | loss = 0.33277323842048645\n",
      "train epoch = 2 | batch = 10 | loss = 0.371238648891449\n",
      "train epoch = 2 | batch = 12 | loss = 0.36446645855903625\n",
      "train epoch = 2 | batch = 14 | loss = 0.36986252665519714\n",
      "train epoch = 2 | batch = 16 | loss = 0.3785508871078491\n",
      "In epoch 2, the train loss is: 0.36395205557346344, the val loss is: 1.2640548348426819\n",
      "train epoch = 3 | batch = 0 | loss = 0.37351301312446594\n",
      "train epoch = 3 | batch = 2 | loss = 0.34409162402153015\n",
      "train epoch = 3 | batch = 4 | loss = 0.3396100103855133\n",
      "train epoch = 3 | batch = 6 | loss = 0.37576189637184143\n",
      "train epoch = 3 | batch = 8 | loss = 0.3576565086841583\n",
      "train epoch = 3 | batch = 10 | loss = 0.28806066513061523\n",
      "train epoch = 3 | batch = 12 | loss = 0.40986868739128113\n",
      "train epoch = 3 | batch = 14 | loss = 0.3833591341972351\n",
      "train epoch = 3 | batch = 16 | loss = 0.3776719272136688\n",
      "In epoch 3, the train loss is: 0.36204364399115246, the val loss is: 1.2933022379875183\n",
      "train epoch = 4 | batch = 0 | loss = 0.3712005615234375\n",
      "train epoch = 4 | batch = 2 | loss = 0.40653759241104126\n",
      "train epoch = 4 | batch = 4 | loss = 0.3455300033092499\n",
      "train epoch = 4 | batch = 6 | loss = 0.3390030860900879\n",
      "train epoch = 4 | batch = 8 | loss = 0.42420801520347595\n",
      "train epoch = 4 | batch = 10 | loss = 0.3533385097980499\n",
      "train epoch = 4 | batch = 12 | loss = 0.3532983660697937\n",
      "train epoch = 4 | batch = 14 | loss = 0.3075627088546753\n",
      "train epoch = 4 | batch = 16 | loss = 0.3971792459487915\n",
      "In epoch 4, the train loss is: 0.36228965388404, the val loss is: 1.2230912446975708\n"
     ]
    }
   ],
   "source": [
    "# create a file to store checkpoint model parameters\n",
    "model_dir = './model_dir/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# frozen all layers and their parameters\n",
    "for param in unet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "\n",
    "    # store the best parameters\n",
    "    best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "    torch.save(unet_model.state_dict(), best_model_params_path)\n",
    "\n",
    "    best_loss = float('Inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # training loop\n",
    "        train_loss = 0\n",
    "        count = 0\n",
    "        unet_model.train()\n",
    "\n",
    "        for idx_batch, (imagergb, _, filename) in enumerate(train_loader):\n",
    "            \n",
    "            # zero the grad of the network before feed-forward\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # send to the device (GPU or CPU) and do a forward pass\n",
    "            x = imagergb.to(device)\n",
    "\n",
    "            # prediction with 14 probs \n",
    "            y = unet_model(x)\n",
    "\n",
    "            # pseudo_labels based on pre-trained model\n",
    "            pseudo_labels = torch.argmax(y, dim=1)\n",
    "\n",
    "            # only update parameters in batch normalization,\n",
    "            # and update statistic data here\n",
    "            for module in unet_model.modules():\n",
    "                if isinstance(module, torch.nn.BatchNorm2d):\n",
    "                    module.train()  \n",
    "\n",
    "            loss = loss_func(y, pseudo_labels)\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx_batch % 2 == 0:\n",
    "                print(\"train epoch = \" + str(epoch) + \" | batch = \" + str(idx_batch) + \" | loss = \"+str(loss.item()))\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        train_loss /= count\n",
    "\n",
    "        # evaluation loop\n",
    "        unet_model.eval()\n",
    "        val_loss = 0\n",
    "        count = 0\n",
    "\n",
    "        for idx_batch, (imagergb, labelmask, filename) in enumerate(val_loader):\n",
    "\n",
    "            with torch.no_grad(): # no gradient required during validation loop\n",
    "                x = imagergb.to(device)\n",
    "                y_ = labelmask.to(device)\n",
    "                y = unet_model(x)\n",
    "                loss = loss_func(y, y_)\n",
    "                val_loss += loss.item()\n",
    "                count += 1\n",
    "\n",
    "        val_loss/=count\n",
    "\n",
    "        # choose the best model with minimal loss\n",
    "        # save parameters to the unet_model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(unet_model.state_dict(), best_model_params_path)\n",
    "\n",
    "        print(f'In epoch {epoch}, the train loss is: {train_loss}, the val loss is: {val_loss}')\n",
    "\n",
    "        # record the parameters at each chechpoint\n",
    "        model_location = model_dir + \"model_file_epoch_\" + str(epoch) + \".pt\"\n",
    "        torch.save(unet_model, model_location)\n",
    "\n",
    "    unet_model.load_state_dict(torch.load(best_model_params_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584c968",
   "metadata": {},
   "source": [
    "## Evaluate cloudy dataset performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc4f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric of accuracy.\n",
    "def global_accuracy_metric(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred)/y_pred.size\n",
    "\n",
    "# evaluation metric of iou.\n",
    "def IoU_metric(y_true, y_pred):\n",
    "\n",
    "    iou_per_image = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        intersection = np.logical_and(y_pred == i, y_true == i).sum()\n",
    "        union = np.logical_or(y_pred == i, y_true == i).sum()\n",
    "        \n",
    "        # if the union is 0, then the iou should be null\n",
    "        # otherwise, the iou is intersection/union\n",
    "        if union == 0:\n",
    "            iou = np.NAN\n",
    "        else:\n",
    "            iou = intersection/union\n",
    "            \n",
    "        iou_per_image.append(iou)\n",
    "\n",
    "    return iou_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e632fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_acc = []\n",
    "perclass_acc = []\n",
    "img_file = []\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "for idx_batch, (imagergb, labelmask, filename) in enumerate(test_loader):\n",
    "\n",
    "    img_file.extend(filename)\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "\n",
    "        x = imagergb.to(device) \n",
    "        y_ = labelmask.to(device) \n",
    "        y = unet_model(x) \n",
    "\n",
    "        for idx in range(0, y.shape[0]):\n",
    "\n",
    "            # choose the most likely label\n",
    "            max_index = torch.argmax(y[idx], dim=0).cpu().int().numpy()\n",
    "            gt_correct_format = y_[idx].cpu().int().numpy()\n",
    "\n",
    "            # calculate the global accuracy of each image\n",
    "            correct_prediction = global_accuracy_metric(gt_correct_format, max_index)\n",
    "            global_acc.append(correct_prediction)\n",
    "\n",
    "            # calculate the iou per class of each image\n",
    "            iou_per_image = IoU_metric(gt_correct_format, max_index)\n",
    "            perclass_acc.append(iou_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1712287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global accuracy overall image is: 0.7122147878011068\n",
      "The average mIoU scores is: 0.32051338053990197\n",
      "\n",
      "The overall IOU scores for class Sky is 0.8191607140651854\n",
      "The overall IOU scores for class Building is 0.47109222447447824\n",
      "The overall IOU scores for class Pole is 0.0\n",
      "The overall IOU scores for class Road is 0.6600544010361143\n",
      "The overall IOU scores for class LaneMarking is 0.15773450144547776\n",
      "The overall IOU scores for class SideWalk is 0.6623841835538951\n",
      "The overall IOU scores for class Pavement is nan\n",
      "The overall IOU scores for class Tree is 0.6254697701298607\n",
      "The overall IOU scores for class SignSymbol is 0.0\n",
      "The overall IOU scores for class Fence is 0.0199589543375284\n",
      "The overall IOU scores for class Car_Bus is 0.48060968842677415\n",
      "The overall IOU scores for class Pedestrian is 0.2662015479132645\n",
      "The overall IOU scores for class Bicyclist is 0.0\n",
      "The overall IOU scores for class Others is 0.004007961636147182\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# print and calculate the global image accuracy \n",
    "print(f'The global accuracy overall image is: {np.mean(global_acc)}')\n",
    "\n",
    "# print and calculate the average mIOU\n",
    "overall_class_iou = np.nanmean(perclass_acc, axis=0)\n",
    "print(f'The average mIoU scores is: {np.nanmean(overall_class_iou)}\\n')\n",
    "\n",
    "# print and calculate the IOU per class\n",
    "for idx in range(num_classes):\n",
    "    print(f'The overall IOU scores for class {labels[idx]} is {overall_class_iou[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
