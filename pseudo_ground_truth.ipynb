{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6e87b0-f10c-49b6-8341-73cd943ffbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 experimentation: Unsupervised domain adaptation using pseudo-ground truth generation\n",
    "# major library dependencies: jupyter, numpy, matplotlib, pytorch, scikit-image, pillow\n",
    "\n",
    "# Fine-tuning with Pseudo-ground Truth\n",
    "import torch\n",
    "from dataset import camvidLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import data_aug as aug\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "from unet import UNet\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imsave\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cpu' # can be set to \"cuda\" if you have a GPU\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "\n",
    "data_root = './CamVid/cloudy'\n",
    "train_data = camvidLoader(root=data_root, split='train', is_aug=False, img_size = [256, 256], is_pytorch_transform=True)\n",
    "test_data = camvidLoader(root=data_root, split='test', is_aug=False, img_size = [256, 256], is_pytorch_transform=True)\n",
    "\n",
    "num_classes = 14 # number of classes is always 14 for this project.\n",
    "labels = ['Sky', 'Building', 'Pole', 'Road', 'LaneMarking', 'SideWalk', 'Pavement', 'Tree', 'SignSymbol', \n",
    "          'Fence', 'Car_Bus', 'Pedestrian', 'Bicyclist', 'Others']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf64955",
   "metadata": {},
   "source": [
    "## Load parameters, model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88764b97-9b73-4939-9468-3090e46817a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hyper parameters\n",
    "batch_size = 4\n",
    "num_workers = 8\n",
    "lr = 5e-6\n",
    "epochs = 5\n",
    "\n",
    "# load train and test dataset\n",
    "train_dataset = camvidLoader(root=data_root, split='train', is_aug=False, img_size = [256, 256], \n",
    "                             is_pytorch_transform = True, aug = None) \n",
    "train_loader = DataLoader(train_dataset, num_workers=num_workers, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_dataset = camvidLoader(root=data_root, split='val', is_aug=False, img_size = [256, 256], \n",
    "                             is_pytorch_transform = True, aug = None) \n",
    "val_loader = DataLoader(train_dataset, num_workers=num_workers, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, num_workers=num_workers, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee2dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pre-trained unet model\n",
    "unet_model = UNet(3, num_classes, width=32, bilinear=True)\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "unet_model.load_state_dict(unet.state_dict())\n",
    "unet_model = unet_model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(unet_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8297e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function that computes the entropy map for the unet output\n",
    "def compute_entropy_map(model_output):\n",
    "\n",
    "    pixel_entropy = []\n",
    "    \n",
    "    for idx in range(0, model_output.shape[0]):\n",
    "    \n",
    "        # output size is 14*256*256\n",
    "        probs = F.softmax(model_output[idx], dim=0)\n",
    "\n",
    "        # calculate the entropy for each pixel\n",
    "        epsilon = 1e-5\n",
    "        entropy = -torch.sum(probs * torch.log(probs + epsilon), dim=0)\n",
    "        pixel_entropy.append(entropy.cpu().detach().numpy())\n",
    "\n",
    "    return pixel_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select prediction with low uncertainty\n",
    "def sel_prediction(y, confidence):\n",
    "\n",
    "\n",
    "    for idx in range(y.shape[0]):\n",
    "\n",
    "        confidence_ = confidence[idx]\n",
    "\n",
    "        # select pixels that with high uncertainty\n",
    "        condition_indices = np.where(confidence_ < -1.96)\n",
    "\n",
    "        # set 0 to selected pixels with 14 channels\n",
    "        for channel in range(14):\n",
    "            y[idx, channel][condition_indices] = 0\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select pseudo labels with low uncertainty\n",
    "def sel_pseudo(pseudo_labels, confidence):\n",
    "\n",
    "    for idx in range(pseudo_labels.shape[0]):\n",
    "\n",
    "        confidence_ = confidence[idx]\n",
    "\n",
    "        # select pixels that with high uncertainty\n",
    "        condition_indices = np.where(confidence_ < -1.96)\n",
    "\n",
    "        # set 0 to selected pixels\n",
    "        pseudo_labels[idx][condition_indices] = 0\n",
    "\n",
    "    return pseudo_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36435fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch = 0 | batch = 0 | loss = 0.37568891048431396\n",
      "train epoch = 0 | batch = 2 | loss = 0.4533589482307434\n",
      "train epoch = 0 | batch = 4 | loss = 0.38332900404930115\n",
      "train epoch = 0 | batch = 6 | loss = 0.42419129610061646\n",
      "train epoch = 0 | batch = 8 | loss = 0.4331427216529846\n",
      "train epoch = 0 | batch = 10 | loss = 0.37523218989372253\n",
      "train epoch = 0 | batch = 12 | loss = 0.42762961983680725\n",
      "train epoch = 0 | batch = 14 | loss = 0.4290653467178345\n",
      "train epoch = 0 | batch = 16 | loss = 0.4671803116798401\n",
      "epoch 0, training loss = 0.4235711478524738\n",
      "train epoch = 1 | batch = 0 | loss = 0.3985866606235504\n",
      "train epoch = 1 | batch = 2 | loss = 0.4785328805446625\n",
      "train epoch = 1 | batch = 4 | loss = 0.4249192476272583\n",
      "train epoch = 1 | batch = 6 | loss = 0.4987383186817169\n",
      "train epoch = 1 | batch = 8 | loss = 0.3791738450527191\n",
      "train epoch = 1 | batch = 10 | loss = 0.4353066682815552\n",
      "train epoch = 1 | batch = 12 | loss = 0.3696546256542206\n",
      "train epoch = 1 | batch = 14 | loss = 0.44727200269699097\n",
      "train epoch = 1 | batch = 16 | loss = 0.37104806303977966\n",
      "epoch 1, training loss = 0.42265592681037056\n",
      "train epoch = 2 | batch = 0 | loss = 0.4533505141735077\n",
      "train epoch = 2 | batch = 2 | loss = 0.3800169825553894\n",
      "train epoch = 2 | batch = 4 | loss = 0.45959728956222534\n",
      "train epoch = 2 | batch = 6 | loss = 0.5039131045341492\n",
      "train epoch = 2 | batch = 8 | loss = 0.44323599338531494\n",
      "train epoch = 2 | batch = 10 | loss = 0.4095042049884796\n",
      "train epoch = 2 | batch = 12 | loss = 0.3737656772136688\n",
      "train epoch = 2 | batch = 14 | loss = 0.37910693883895874\n",
      "train epoch = 2 | batch = 16 | loss = 0.43666160106658936\n",
      "epoch 2, training loss = 0.42973139385382336\n",
      "train epoch = 3 | batch = 0 | loss = 0.41616830229759216\n",
      "train epoch = 3 | batch = 2 | loss = 0.4775804877281189\n",
      "train epoch = 3 | batch = 4 | loss = 0.38621607422828674\n",
      "train epoch = 3 | batch = 6 | loss = 0.4066210687160492\n",
      "train epoch = 3 | batch = 8 | loss = 0.4639206826686859\n",
      "train epoch = 3 | batch = 10 | loss = 0.4396430552005768\n",
      "train epoch = 3 | batch = 12 | loss = 0.42162150144577026\n",
      "train epoch = 3 | batch = 14 | loss = 0.4136736989021301\n",
      "train epoch = 3 | batch = 16 | loss = 0.47713494300842285\n",
      "epoch 3, training loss = 0.4297421591149436\n",
      "train epoch = 4 | batch = 0 | loss = 0.4334242343902588\n",
      "train epoch = 4 | batch = 2 | loss = 0.37233734130859375\n",
      "train epoch = 4 | batch = 4 | loss = 0.41764700412750244\n",
      "train epoch = 4 | batch = 6 | loss = 0.43382635712623596\n",
      "train epoch = 4 | batch = 8 | loss = 0.4378061294555664\n",
      "train epoch = 4 | batch = 10 | loss = 0.5098916292190552\n",
      "train epoch = 4 | batch = 12 | loss = 0.42009058594703674\n",
      "train epoch = 4 | batch = 14 | loss = 0.49754980206489563\n",
      "train epoch = 4 | batch = 16 | loss = 0.4273747205734253\n",
      "epoch 4, training loss = 0.4280163562960095\n"
     ]
    }
   ],
   "source": [
    "# create a file to store checkpoint model parameters\n",
    "model_dir = './model_dir/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "\n",
    "    # the path to store the best parameters\n",
    "    best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "    torch.save(unet_model.state_dict(), best_model_params_path)\n",
    "\n",
    "    best_loss = float('Inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # start trainning loop\n",
    "        unet_model.train()\n",
    "        train_loss = 0\n",
    "        count = 0\n",
    "\n",
    "        for idx_batch, (imagergb, _, filename) in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # send to the device (GPU or CPU) and do a forward pass\n",
    "            x = imagergb.to(device)\n",
    "\n",
    "            # pretained unet model to predict y\n",
    "            y = unet_model(x)\n",
    "            \n",
    "            # calculate entropy map here. \n",
    "            entropy = compute_entropy_map(y)\n",
    "            confidence = [-x for x in entropy] \n",
    "\n",
    "            # predict the pseudo labels at each pixel\n",
    "            pseudo_labels = torch.argmax(y, dim=1)\n",
    "\n",
    "            # find y and pseudo labels with high confidence\n",
    "            y_high_conf = sel_prediction(y, confidence)\n",
    "            pseudo_labels_high_conf = sel_pseudo(pseudo_labels, confidence)\n",
    "\n",
    "            # finally calculate the loss and back propagate\n",
    "            loss = loss_func(y_high_conf, pseudo_labels_high_conf)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx_batch % 2 == 0:\n",
    "                print(\"train epoch = \" + str(epoch) + \" | batch = \" + str(idx_batch) + \" | loss = \"+str(loss.item()))\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        train_loss /= count\n",
    "\n",
    "        # store the best parameters when the loss is mininal\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            torch.save(unet_model.state_dict(), best_model_params_path)\n",
    "\n",
    "        print('epoch ' + str(epoch) + ', training loss = ' + str(train_loss))\n",
    "\n",
    "        # store the check point parameters into dir\n",
    "        model_location = model_dir + \"model_file_epoch_\" + str(epoch) + \".pt\"\n",
    "        torch.save(unet_model, model_location)\n",
    "\n",
    "    # import the best parameters to unet model\n",
    "    unet_model.load_state_dict(torch.load(best_model_params_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e093e29",
   "metadata": {},
   "source": [
    "## Evaluate cloudy dataset performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d1d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric of accuracy.\n",
    "def global_accuracy_metric(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred)/y_pred.size\n",
    "\n",
    "# evaluation metric of iou.\n",
    "def IoU_metric(y_true, y_pred):\n",
    "\n",
    "    iou_per_image = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        intersection = np.logical_and(y_pred == i, y_true == i).sum()\n",
    "        union = np.logical_or(y_pred == i, y_true == i).sum()\n",
    "        \n",
    "        # if the union is 0, then the iou should be null\n",
    "        # otherwise, the iou is intersection/union\n",
    "        if union == 0:\n",
    "            iou = np.NAN\n",
    "        else:\n",
    "            iou = intersection/union\n",
    "            \n",
    "        iou_per_image.append(iou)\n",
    "\n",
    "    return iou_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d441aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_acc = []\n",
    "perclass_acc = []\n",
    "img_file = []\n",
    "\n",
    "# start evaluation\n",
    "unet_model.eval()\n",
    "\n",
    "for idx_batch, (imagergb, labelmask, filename) in enumerate(test_loader):\n",
    "\n",
    "    img_file.extend(filename)\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "\n",
    "        x = imagergb.to(device) \n",
    "        y_ = labelmask.to(device) \n",
    "        y = unet_model(x)\n",
    "\n",
    "        for idx in range(0, y.shape[0]):\n",
    "\n",
    "            # choose the most likely label\n",
    "            max_index = torch.argmax(y[idx], dim=0).cpu().int().numpy()\n",
    "            gt_correct_format = y_[idx].cpu().int().numpy()\n",
    "\n",
    "            # calculate the global accuracy of each image\n",
    "            correct_prediction = global_accuracy_metric(gt_correct_format, max_index)\n",
    "            global_acc.append(correct_prediction)\n",
    "\n",
    "            # calculate the iou per class of each image\n",
    "            iou_per_image = IoU_metric(gt_correct_format, max_index)\n",
    "            perclass_acc.append(iou_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43ee7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global accuracy overall image is: 0.7224432627360026\n",
      "The average mIoU scores is: 0.3300943880664946\n",
      "\n",
      "The overall IOU scores for class Sky is 0.863187620143021\n",
      "The overall IOU scores for class Building is 0.4815343172450504\n",
      "The overall IOU scores for class Pole is 0.0\n",
      "The overall IOU scores for class Road is 0.6294435525621992\n",
      "The overall IOU scores for class LaneMarking is 0.1297391690535898\n",
      "The overall IOU scores for class SideWalk is 0.7259996840837188\n",
      "The overall IOU scores for class Pavement is nan\n",
      "The overall IOU scores for class Tree is 0.6299893687837966\n",
      "The overall IOU scores for class SignSymbol is 0.0\n",
      "The overall IOU scores for class Fence is 0.005950273496382147\n",
      "The overall IOU scores for class Car_Bus is 0.525398801338756\n",
      "The overall IOU scores for class Pedestrian is 0.2916169040041272\n",
      "The overall IOU scores for class Bicyclist is 0.0\n",
      "The overall IOU scores for class Others is 0.008367354153787494\n"
     ]
    }
   ],
   "source": [
    "# print and calculate the global image accuracy \n",
    "print(f'The global accuracy overall image is: {np.mean(global_acc)}')\n",
    "\n",
    "# print and calculate the average mIOU\n",
    "overall_class_iou = np.nanmean(perclass_acc, axis=0)\n",
    "print(f'The average mIoU scores is: {np.nanmean(overall_class_iou)}\\n')\n",
    "\n",
    "# print and calculate the IOU per class\n",
    "for idx in range(num_classes):\n",
    "    print(f'The overall IOU scores for class {labels[idx]} is {overall_class_iou[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
